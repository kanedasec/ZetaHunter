services:
  ollama:
    image: ollama/ollama:latest
    container_name: zetahunter-ollama
    ports:
      - "11434:11434"
    volumes:
      - ./ollama:/root/.ollama   # persiste modelos no host
    restart: unless-stopped
    entrypoint: [ "ollama", "serve" ]

  pentestgpt:
    build:
      context: ./infra/pentestgpt
      dockerfile: Dockerfile
    container_name: zetahunter-pentestgpt
    env_file: .env
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_MODEL: ${OLLAMA_MODEL}
      CHATGPT_COOKIE: disabled
      GEMINI_API_KEY: disabled
      DEEPSEEK_API_KEY: disabled
    depends_on:
      - ollama
    ports:
      - "8080:8080"        # se quiser acessar de fora; opcional
    restart: unless-stopped

  web:
    build:
      context: .
      dockerfile: infra/web/Dockerfile
    env_file: .env
    environment:
      - OPENAI_API_KEY
        - OPENAI_MODEL
        - OPENAI_FORCE_MOCK
        - AI_PROVIDER                 
        - OLLAMA_HOST                 
        - OLLAMA_MODEL              
        - DB_PATH=/app/data/app.db
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - ./backend/examples:/app/examples
      - ./data:/app/data
    depends_on:
      - runner
      - ollama

  runner:
    build:
      context: .
      dockerfile: infra/runner/Dockerfile
    env_file: .env
    environment:
      - RUNNER_TIMEOUT
      - ALLOWED_TARGETS
    volumes:
      - ./runner:/runner

  minio:
    image: minio/minio:latest
    command: server /data
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
    volumes:
      - minio_data:/data

volumes:
  minio_data:
