# Zeta Hunter â€” MVP structure

> Orquestrador de automaÃ§Ã£o de bug bounty baseado em PentestGPT + OpenAI GPT-5.

---

## Objetivo

Criar um MVP que permita a um usuÃ¡rio autorizado executar *playbooks* de seguranÃ§a em ambientes autorizados, utilizando:

* PentestGPT (input de passos/estratÃ©gia)
* OpenAI GPT-5 (geraÃ§Ã£o de scripts PoC / scanners)
* Executor isolado (containers efÃªmeros) que roda o script em sandbox
* Loop de feedback entre executor -> analyzer -> PentestGPT

Este repositÃ³rio contÃ©m a estrutura inicial do projeto (esqueleto), templates de prompt, e um `README.md` com instruÃ§Ãµes para rodar localmente em modo *lab* (somente targets autorizados, por padrÃ£o `localhost`).

---

## Estrutura de pastas (proposta)

```
bug-hunter-ai/
â”œâ”€â”€ README.md
â”œâ”€â”€ .env.example
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ infra/
â”‚   â”œâ”€â”€ runner/Dockerfile
â”‚   â””â”€â”€ web/Dockerfile
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints.py
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”‚   â””â”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â”‚   â”œâ”€â”€ queue.py
â”‚   â”‚   â”‚   â””â”€â”€ executor.py
â”‚   â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”‚   â”œâ”€â”€ safe_poc_template.txt
â”‚   â”‚   â”‚   â””â”€â”€ pentestgpt_adapter.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ models.sql (sqlite schema)
â”‚   â”‚   â””â”€â”€platbooks/
â”‚   â”‚       â””â”€â”€ basic-recon.yml
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ runner/
â”‚   â”œâ”€â”€ run_script.sh
â”‚   â””â”€â”€ runner-entrypoint.py
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ (opcional) basic UI placeholder
â””â”€â”€ docs/
    â”œâ”€â”€ PROMPTS.md
    â””â”€â”€ SECURITY.md
```

---

## ðŸ§© Linha do tempo do que jÃ¡ foi feito
# Etapa	Status	DescriÃ§Ã£o
1. Setup e estrutura inicial:	CriaÃ§Ã£o da base FastAPI + Docker + executor independente (executor.py).
2. ExecuÃ§Ã£o local de playbooks:	Implementado basic-recon.yml com http_get e run_script (rodando juice_shop_test.py).
3. OrquestraÃ§Ã£o de jobs (API):	Endpoint /jobs cria e executa playbook, retornando JSON.
4. ValidaÃ§Ã£o de targets seguros:	Campo ALLOWED_TARGETS no .env controla onde Ã© permitido executar.
5. Path resolving container/host:	Corrigido para funcionar tanto local quanto dentro do container.
6. Docker Compose + Juice Shop:	Ambiente completo para testes (web, runner, minio, juice-shop).
7. PersistÃªncia mÃ­nima (SQLite):	Jobs gravados em data/app.db, listagem e consulta funcionando (/jobs, /jobs/{id}).
8. Retorno estruturado JSON:	Executor retorna resultados por step, com evidÃªncias e status.

## ðŸš§ Etapas que ainda faltam (inÃ­cio da fase de IA)
9. IntegraÃ§Ã£o com OpenAI (GPT-5):	Fazer o backend gerar scripts automaticamente com base em prompts e contexto do target (exemplo: "escreva um script Python que teste XSS bÃ¡sico").
10. PentestGPT adapter:	Criar um mÃ³dulo que traduz a resposta do PentestGPT em playbooks YAML â€” ou seja, a IA descreve o plano de ataque, e o sistema transforma isso em steps executÃ¡veis.
11. SeguranÃ§a da geraÃ§Ã£o:	Adicionar filtros (blacklist de comandos, sandbox, timeout, etc.) antes de executar qualquer cÃ³digo gerado.
12. Auditoria de IA:	Registrar cada prompt enviado, resposta do modelo e script gerado no banco (para rastreabilidade).
13. Interface web (dashboard): Painel para visualizar jobs, logs, resultados e evidÃªncias.
14. Pipeline de automaÃ§Ã£o completa:	Unir: input de target â†’ PentestGPT cria plano â†’ OpenAI gera scripts â†’ executor executa â†’ resultados retornam ao PentestGPT para decisÃ£o do prÃ³ximo passo.

---
## Arquivos e diretÃ³rios â€” explicaÃ§Ã£o detalhada
### README.md

ConteÃºdo: instruÃ§Ãµes rÃ¡pidas de quickstart, comandos Docker Compose, seguranÃ§a bÃ¡sica e prÃ³ximos passos.

Uso: primeiro ponto de referÃªncia para rodar o projeto em laboratÃ³rio.

### .env.example

VariÃ¡veis de ambiente de exemplo:

OPENAI_API_KEY â€” chave OpenAI (opcional no MVP local).

ALLOWED_TARGETS â€” lista comma-separated de hosts/aliases permitidos (ex: localhost,127.0.0.1,juice-shop). ObrigatÃ³rio para seguranÃ§a.

RUNNER_TIMEOUT â€” timeout padrÃ£o (segundos) para execuÃ§Ã£o de scripts.

MINIO_* â€” placeholders para storage de artefatos (MinIO).

Deve ser copiado para .env e ajustado conforme ambiente local.

### .gitignore

PadrÃµes para Python, IDEs, ambientes virtuais, arquivos temporÃ¡rios e secrets (inclui .env).

### docker-compose.yml

Orquestra trÃªs serviÃ§os principais:

web â€” imagem construÃ­da a partir de infra/web/Dockerfile que executa o FastAPI (backend).

runner â€” imagem construÃ­da a partir de infra/runner/Dockerfile (container de suporte / runner).

minio â€” armazenamento de objetos (opcional, usado como artifact store).

ObservaÃ§Ãµes: configurado para usar env_file: .env (recomendado) e para montar ./backend:/app e ./examples:/app/examples (quando for usado). Se montar ./backend:/app, atenÃ§Ã£o: conteÃºdo copiado pela imagem pode ser sobrescrito pelo volume, por isso tambÃ©m montamos examples para tornar scripts disponÃ­veis.

### docker-compose.juice.yml

Arquivo simples para subir o OWASP Juice Shop.

### infra/web/Dockerfile

Imagem base python:3.11-slim.

Instala dependÃªncias listadas em backend/requirements.txt.

Copia backend/ para /app e examples/ para /app/examples.

Comando de inicializaÃ§Ã£o: uvicorn app.main:app --host 0.0.0.0 --port 8000.

Nota: quando vocÃª montar ./backend:/app como volume, ele substitui o conteÃºdo copiado na imagem â€” por isso a cÃ³pia de examples e o volume ./examples:/app/examples sÃ£o importantes para garantir que os scripts de exemplo fiquem disponÃ­veis em ambiente de desenvolvimento.

### infra/runner/Dockerfile

Imagem base python:3.11-slim.

Instala utilitÃ¡rios (bash, jq, psmisc).

Copia a pasta runner/ para /runner.

Entrypoint: runner-entrypoint.py (mantÃ©m container up; foi pensado para testes).

### backend/requirements.txt

DependÃªncias do backend:

fastapi, uvicorn[standard], httpx, pydantic, python-dotenv, pyyaml.

Use esse arquivo para criar ambientes ou imagens.

### backend/app/main.py

Inicializa FastAPI; inclui roteador (endpoints.py) e rota /health.

Ponto de entrada da aplicaÃ§Ã£o.

### backend/app/api/endpoints.py

Implementa:

POST /jobs â€” cria e executa um job. No MVP atual o endpoint:

valida target contra ALLOWED_TARGETS,

resolve caminhos do executor/playbook tanto para execuÃ§Ã£o local quanto para container,

executa executor.py via subprocess (blocking) e retorna job_id, status e result (JSON jÃ¡ do executor).

GET /jobs/{job_id} â€” consulta o job em memÃ³ria (JOBS dict).

ObservaÃ§Ãµes:

Jobs sÃ£o mantidos em memÃ³ria (dentro do processo). Se reiniciar o container, o histÃ³rico se perde â€” persistÃªncia em SQLite Ã© um prÃ³ximo passo.

O endpoint foi escrito para ser tolerante com dois layouts (host vs container) para facilitar desenvolvimento.

### backend/app/workers/executor.py

Executor de playbooks (script Python):

Leitura do playbook YAML (usa pyyaml).

Suporta tipos de steps:

http_get â€” faz GET para target + path, coleta status, tÃ­tulo HTML e um sample do conteÃºdo.

run_script â€” executa um script local (ex.: examples/juice_shop_test.py) e espera que o script imprima JSON com evidence, stdout e exit_code.

Resolve paths de forma robusta entre container/host.

Retorna JSON consolidado com playbook, target e lista steps com resultados.

### backend/playbooks/basic-recon.yml

Exemplo de playbook YAML utilizado no MVP.

Type suportados no MVP: http_get, run_script. Novos tipos (e.g., nmap, nuclei) podem ser mapeados no executor.

### backend/app/prompts/safe_poc_template.txt

Template de prompt seguro (texto). Planejado para ser usado quando a integraÃ§Ã£o com OpenAI for adicionada.

ContÃ©m restriÃ§Ãµes: no reverse shells, timeout, output JSON etc.

Onde editar: backend/app/prompts/.

### backend/app/models/models.sql

Esquema SQL inicial sugerido (placeholder) com tabelas para users, targets, jobs, job_steps, artifacts, audit_logs.

NÃ£o hÃ¡ integraÃ§Ã£o ativa â€” serve de guia para quando adicionarmos persistÃªncia (SQLite/Postgres).

### runner/run_script.sh

Script shell simples usado originalmente no MVP como wrapper que executa python3 <script> com timeout.

No fluxo atual o executor.py chama diretamente o script Python (saÃ­da JSON).

### runner/runner-entrypoint.py

MantÃ©m o container runner em execuÃ§Ã£o (apenas print('runner container up') e sleep loop). EstÃ¡ preparado para evoluir para um serviÃ§o que executa jobs via API/queue.

### examples/juice_shop_test.py

Script de teste safe para Juice Shop (lab):

Faz GET / e GET /rest/user/login.

Extrai tÃ­tulo HTML atravÃ©s de um parser simples.

Produz JSON com evidence, stdout e exit_code.

Projetado para ser nÃ£o destrutivo (apenas probes).

### docs/PROMPTS.md e docs/SECURITY.md

PROMPTS.md: orientaÃ§Ãµes para criaÃ§Ã£o de prompts seguros (quando integrar GPT).

SECURITY.md: notas com recomendaÃ§Ãµes importantes (ALLOWED_TARGETS obrigatÃ³rio, runner hardened, armazenamento seguro de chaves).

## Formato do playbook (explicaÃ§Ã£o)

Arquivo YAML com:

name, description â€” metadados.

steps â€” lista ordenada de aÃ§Ãµes.

Cada step contem:

id â€” identificador.

type â€” http_get ou run_script (MVP).

params â€” parÃ¢metros (ex: path para http_get, script para run_script).

O executor percorre steps na ordem e agrega result para cada step.

## Onde alterar/estender o que foi feito

### Adicionar novos tipos de step:

editar backend/app/workers/executor.py e acrescentar lÃ³gica para tipos (ex: nmap, nuclei, amass) â€” lembre de isolar execuÃ§Ãµes.

### Integrar OpenAI (script generation):

Template: backend/app/prompts/safe_poc_template.txt.

Chamadas ao OpenAI devem ser feitas no backend (novo mÃ³dulo generator.py ou dentro do worker), armazenando prompts/outputs em audit logs e aplicando validaÃ§Ãµes/blacklist antes de executar.

### PentestGPT adapter:

Arquivo sugerido: backend/app/prompts/pentestgpt_adapter.py (ainda nÃ£o implementado). Ele deve transformar passos em playbooks YAML.

### PersistÃªncia:

Implementar SQLite/Postgres; migrar JOBS (dict mem) para DB usando models.sql como guia.

### Fila e workers:

Atualmente o POST /jobs chama o executor de forma sÃ­ncrona. Para produÃ§Ã£o, introduzir Celery/RQ + workers para nÃ£o bloquear o servidor.

### Hardening do runner:

Substituir execuÃ§Ã£o por microVM (Firecracker) ou usar rootless containers + seccomp profile + AppArmor.

Restringir rede: permitir apenas conexÃµes para hosts/ips do scope.

Monitorar syscalls via eBPF para detectar comportamento malicioso.

## O que foi implementado atÃ© aqui (resumo operacional)

FastAPI backend com endpoints /jobs e /jobs/{job_id}.

Executor (executor.py) capaz de rodar playbooks com http_get e run_script.

Playbook de exemplo basic-recon.yml.

Script de teste examples/juice_shop_test.py (safe).

Docker setup (web, runner e MinIO) + compose file para Juice Shop.

PermissÃµes e path handling entre host e container resolvidos.

Template de prompt seguro para futura integraÃ§Ã£o com OpenAI.

ZIP gerado com todo esqueleto pronto para compartilhar.

## PrÃ³ximos passos recomendados (prioridade)

PersistÃªncia mÃ­nima (SQLite) para jobs/resultados.

Fila assÃ­ncrona (RQ/Celery) para nÃ£o bloquear FastAPI.

Implementar/validar OpenAI generation + blacklist e auditoria.

Hardening do executor (seccomp/AppArmor ou microVM).

Adicionar CI (linters, SCA, Trivy) e testes automatizados.